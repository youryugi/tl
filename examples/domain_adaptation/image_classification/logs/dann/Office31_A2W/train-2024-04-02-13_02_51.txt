Namespace(root='data/officecaltech', data='OfficeCaltech', source=['A'], target=['W'], train_resizing='default', val_resizing='default', resize_size=224, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], no_hflip=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), arch='resnet50', bottleneck_dim=256, no_pool=False, scratch=False, trade_off=1.0, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=20, iters_per_epoch=1000, print_freq=100, seed=1, per_class_eval=False, log='logs/dann/Office31_A2W', phase='train')
C:\Users\79152\Desktop\Transfer-Learning-Library-master\examples\domain_adaptation\image_classification\dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
train_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to C:\Users\79152/.cache\torch\hub\checkpoints\resnet50-19c8e357.pth
  0%|                                                                                                                                                                            | 0.00/97.8M [00:00<?, ?B/s]  3%|####2                                                                                                                                                              | 2.56M/97.8M [00:00<00:03, 26.6MB/s]  6%|#########                                                                                                                                                          | 5.44M/97.8M [00:00<00:03, 28.7MB/s]  9%|##############5                                                                                                                                                    | 8.71M/97.8M [00:00<00:03, 31.1MB/s] 12%|####################1                                                                                                                                              | 12.1M/97.8M [00:00<00:02, 32.6MB/s] 16%|#########################8                                                                                                                                         | 15.5M/97.8M [00:00<00:02, 33.7MB/s] 19%|###############################4                                                                                                                                   | 18.9M/97.8M [00:00<00:02, 34.1MB/s] 23%|####################################8                                                                                                                              | 22.1M/97.8M [00:00<00:02, 34.0MB/s] 26%|##########################################2                                                                                                                        | 25.4M/97.8M [00:00<00:02, 31.0MB/s] 29%|###############################################2                                                                                                                   | 28.4M/97.8M [00:00<00:02, 29.9MB/s] 32%|####################################################                                                                                                               | 31.2M/97.8M [00:01<00:02, 28.8MB/s] 35%|#########################################################4                                                                                                         | 34.5M/97.8M [00:01<00:02, 30.1MB/s] 38%|##############################################################3                                                                                                    | 37.4M/97.8M [00:01<00:02, 30.4MB/s] 42%|####################################################################2                                                                                              | 40.9M/97.8M [00:01<00:01, 32.1MB/s] 45%|#########################################################################9                                                                                         | 44.3M/97.8M [00:01<00:01, 33.2MB/s] 49%|###############################################################################7                                                                                   | 47.8M/97.8M [00:01<00:01, 34.2MB/s] 52%|#####################################################################################2                                                                             | 51.1M/97.8M [00:01<00:01, 34.3MB/s] 56%|##########################################################################################7                                                                        | 54.4M/97.8M [00:01<00:01, 33.9MB/s] 59%|################################################################################################1                                                                  | 57.6M/97.8M [00:01<00:01, 31.5MB/s] 63%|######################################################################################################6                                                            | 61.5M/97.8M [00:01<00:01, 34.0MB/s] 66%|############################################################################################################                                                       | 64.8M/97.8M [00:02<00:01, 32.8MB/s] 70%|##################################################################################################################6                                                | 68.8M/97.8M [00:02<00:00, 35.1MB/s] 74%|#########################################################################################################################2                                         | 72.7M/97.8M [00:02<00:00, 36.8MB/s] 78%|###############################################################################################################################1                                   | 76.3M/97.8M [00:02<00:00, 35.1MB/s] 82%|#####################################################################################################################################3                             | 80.0M/97.8M [00:02<00:00, 36.1MB/s] 86%|###########################################################################################################################################8                       | 83.9M/97.8M [00:02<00:00, 37.2MB/s] 90%|##################################################################################################################################################6                | 88.0M/97.8M [00:02<00:00, 38.7MB/s] 94%|########################################################################################################################################################8          | 91.7M/97.8M [00:02<00:00, 38.8MB/s] 98%|###############################################################################################################################################################3   | 95.5M/97.8M [00:02<00:00, 39.2MB/s]100%|###################################################################################################################################################################| 97.8M/97.8M [00:03<00:00, 34.1MB/s]
lr: 0.001
Traceback (most recent call last):
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\examples\domain_adaptation\image_classification\dann.py", line 266, in <module>
    main(args)
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\examples\domain_adaptation\image_classification\dann.py", line 116, in main
    train(train_source_iter, train_target_iter, classifier, domain_adv, optimizer,
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\examples\domain_adaptation\image_classification\dann.py", line 174, in train
    transfer_loss = domain_adv(f_s, f_t)
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\venv\lib\site-packages\torch\nn\modules\module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "c:\users\79152\desktop\transfer-learning-library-master\tllib\alignment\dann.py", line 72, in forward
    f = self.grl(torch.cat((f_s, f_t), dim=0))
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\venv\lib\site-packages\torch\nn\modules\module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "c:\users\79152\desktop\transfer-learning-library-master\tllib\modules\grl.py", line 71, in forward
    coeff = np.float(
  File "C:\Users\79152\Desktop\Transfer-Learning-Library-master\venv\lib\site-packages\numpy\__init__.py", line 353, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
